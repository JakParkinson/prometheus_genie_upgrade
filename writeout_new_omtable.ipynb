{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Generate a complete om.map file that includes all DOMs from the geometry file.\n",
    "- Preserves existing upgrade DOM types (3, 4) from current om.map\n",
    "- Sets all other DOMs to type 2 (standard IceCube DOMs)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating complete om.map file...\n",
      "Reading geometry file...\n",
      "Found 5783 DOMs in geometry file\n",
      "Reading existing om.map...\n",
      "Found 623 DOMs with existing types\n",
      "Created backup: /groups/icecube/jackp/prometheus_genie_cleaned/harvard-prometheus/resources/PPC_tables/upgrade_tables/om.map.backup\n",
      "Generating complete om.map...\n",
      "Complete om.map written to: /groups/icecube/jackp/prometheus_genie_cleaned/harvard-prometheus/resources/PPC_tables/upgrade_tables/om.map.new\n",
      "\n",
      "Summary of DOM types:\n",
      "  Type 1 (Standard IceCube DOM): 5160 DOMs\n",
      "  Type 3 (mDOM (upgrade)): 357 DOMs\n",
      "  Type 4 (DEgg (upgrade)): 266 DOMs\n",
      "\n",
      "To use the new om.map file:\n",
      "mv /groups/icecube/jackp/prometheus_genie_cleaned/harvard-prometheus/resources/PPC_tables/upgrade_tables/om.map.new /groups/icecube/jackp/prometheus_genie_cleaned/harvard-prometheus/resources/PPC_tables/upgrade_tables/om.map\n",
      "\n",
      "Then run your simulation again with NEXTGENDIR set.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Generate a complete om.map file that includes all DOMs from the geometry file.\n",
    "- Preserves existing upgrade DOM types (3, 4) from current om.map\n",
    "- Sets all other DOMs to type 1 (standard IceCube DOMs)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# File paths\n",
    "geo_file = \"/groups/icecube/jackp/prometheus_genie_cleaned/harvard-prometheus/resources/geofiles/icecube_upgrade_new.geo\"\n",
    "existing_om_map = \"blank_om.map\"\n",
    "output_om_map = \"om.map.new\"\n",
    "\n",
    "def read_geometry_file(geo_file):\n",
    "    \"\"\"Read geometry file and extract string_id, dom_id pairs\"\"\"\n",
    "    doms = []\n",
    "    with open(geo_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            # Skip comments and empty lines\n",
    "            if line.startswith('#') or not line:\n",
    "                continue\n",
    "            \n",
    "            parts = line.split()\n",
    "            if len(parts) >= 5:\n",
    "                # Format: x y z string_id dom_id\n",
    "                string_id = int(parts[3])\n",
    "                dom_id = int(parts[4])\n",
    "                doms.append((string_id, dom_id))\n",
    "    \n",
    "    return doms\n",
    "\n",
    "def read_existing_om_map(om_map_file):\n",
    "    \"\"\"Read existing om.map and return dict of (string, dom) -> type\"\"\"\n",
    "    existing_types = {}\n",
    "    \n",
    "    if os.path.exists(om_map_file):\n",
    "        with open(om_map_file, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#'):\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 3:\n",
    "                        string_id = int(parts[0])\n",
    "                        dom_id = int(parts[1])\n",
    "                        dom_type = int(parts[2])\n",
    "                        existing_types[(string_id, dom_id)] = dom_type\n",
    "    \n",
    "    return existing_types\n",
    "\n",
    "def generate_complete_om_map(geo_file, existing_om_map, output_file):\n",
    "    \"\"\"Generate complete om.map preserving existing types\"\"\"\n",
    "    \n",
    "    print(\"Reading geometry file...\")\n",
    "    all_doms = read_geometry_file(geo_file)\n",
    "    print(f\"Found {len(all_doms)} DOMs in geometry file\")\n",
    "    \n",
    "    print(\"Reading existing om.map...\")\n",
    "    existing_types = read_existing_om_map(existing_om_map)\n",
    "    print(f\"Found {len(existing_types)} DOMs with existing types\")\n",
    "    \n",
    "    # Create backup of original om.map\n",
    "    if os.path.exists(existing_om_map):\n",
    "        backup_file = existing_om_map + \".backup\"\n",
    "        import shutil\n",
    "        shutil.copy2(existing_om_map, backup_file)\n",
    "        print(f\"Created backup: {backup_file}\")\n",
    "    \n",
    "    print(\"Generating complete om.map...\")\n",
    "    with open(output_file, 'w') as f:\n",
    "        # Write header comment\n",
    "        f.write(\"# string_id dom_id type_id\\n\")\n",
    "        f.write(\"# Generated automatically - preserves upgrade types, sets others to type 1\\n\")\n",
    "        \n",
    "        for string_id, dom_id in sorted(all_doms):\n",
    "            if (string_id, dom_id) in existing_types:\n",
    "                # Use existing type (3 or 4 for upgrade DOMs)\n",
    "                dom_type = existing_types[(string_id, dom_id)]\n",
    "            else:\n",
    "                # Set to type 1 (standard IceCube DOM)\n",
    "                dom_type = 1\n",
    "            \n",
    "            f.write(f\"{string_id} {dom_id} {dom_type}\\n\")\n",
    "    \n",
    "    print(f\"Complete om.map written to: {output_file}\")\n",
    "    \n",
    "    # Show summary\n",
    "    type_counts = {}\n",
    "    with open(output_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if not line.startswith('#') and line.strip():\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 3:\n",
    "                    dom_type = int(parts[2])\n",
    "                    type_counts[dom_type] = type_counts.get(dom_type, 0) + 1\n",
    "    \n",
    "    print(\"\\nSummary of DOM types:\")\n",
    "    for dom_type, count in sorted(type_counts.items()):\n",
    "        type_name = {\n",
    "            1: \"Standard IceCube DOM\",\n",
    "            3: \"mDOM (upgrade)\",  \n",
    "            4: \"DEgg (upgrade)\"\n",
    "        }.get(dom_type, f\"Type {dom_type}\")\n",
    "        print(f\"  Type {dom_type} ({type_name}): {count} DOMs\")\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Generating complete om.map file...\")\n",
    "    output_file = generate_complete_om_map(geo_file, existing_om_map, output_om_map)\n",
    "    \n",
    "    print(f\"\\nTo use the new om.map file:\")\n",
    "    print(f\"mv {output_file} {existing_om_map}\")\n",
    "    print(\"\\nThen run your simulation again with NEXTGENDIR set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating complete om.map file...\n",
      "Reading geometry file...\n",
      "Found 5783 DOMs in geometry file\n",
      "Reading existing om.map...\n",
      "Found 0 DOMs with existing types\n",
      "Generating complete om.map...\n",
      "Complete om.map written to: om.map.new\n",
      "\n",
      "Summary of DOM types:\n",
      "  Type 1 (Standard IceCube DOM): 5783 DOMs\n",
      "\n",
      "To use the new om.map file:\n",
      "mv om.map.new blank_om.map\n",
      "\n",
      "Then run your simulation again with NEXTGENDIR set.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Generate a complete om.map file that includes all DOMs from the geometry file.\n",
    "- Preserves existing upgrade DOM types (3, 4) from current om.map\n",
    "- Sets all other DOMs to type 1 (standard IceCube DOMs)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# File paths\n",
    "geo_file = \"/groups/icecube/jackp/prometheus_genie_cleaned/harvard-prometheus/resources/geofiles/icecube_upgrade_new.geo\"\n",
    "existing_om_map = \"blank_om.map\"\n",
    "output_om_map = \"om.map.new\"\n",
    "\n",
    "def read_geometry_file(geo_file):\n",
    "    \"\"\"Read geometry file and extract string_id, dom_id pairs\"\"\"\n",
    "    doms = []\n",
    "    with open(geo_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            # Skip comments and empty lines\n",
    "            if line.startswith('#') or not line:\n",
    "                continue\n",
    "            \n",
    "            parts = line.split()\n",
    "            if len(parts) >= 5:\n",
    "                # Format: x y z string_id dom_id\n",
    "                string_id = int(parts[3])\n",
    "                dom_id = int(parts[4])\n",
    "                doms.append((string_id, dom_id))\n",
    "    \n",
    "    return doms\n",
    "\n",
    "def read_existing_om_map(om_map_file):\n",
    "    \"\"\"Read existing om.map and return dict of (string, dom) -> type\"\"\"\n",
    "    existing_types = {}\n",
    "    \n",
    "    if os.path.exists(om_map_file):\n",
    "        with open(om_map_file, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#'):\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 3:\n",
    "                        string_id = int(parts[0])\n",
    "                        dom_id = int(parts[1])\n",
    "                        dom_type = int(parts[2])\n",
    "                        existing_types[(string_id, dom_id)] = dom_type\n",
    "    \n",
    "    return existing_types\n",
    "\n",
    "def generate_complete_om_map(geo_file, existing_om_map, output_file):\n",
    "    \"\"\"Generate complete om.map preserving existing types\"\"\"\n",
    "    \n",
    "    print(\"Reading geometry file...\")\n",
    "    all_doms = read_geometry_file(geo_file)\n",
    "    print(f\"Found {len(all_doms)} DOMs in geometry file\")\n",
    "    \n",
    "    print(\"Reading existing om.map...\")\n",
    "    existing_types = read_existing_om_map(existing_om_map)\n",
    "    print(f\"Found {len(existing_types)} DOMs with existing types\")\n",
    "    \n",
    "    # Create backup of original om.map\n",
    "    if os.path.exists(existing_om_map):\n",
    "        backup_file = existing_om_map + \".backup\"\n",
    "        import shutil\n",
    "        shutil.copy2(existing_om_map, backup_file)\n",
    "        print(f\"Created backup: {backup_file}\")\n",
    "    \n",
    "    print(\"Generating complete om.map...\")\n",
    "    with open(output_file, 'w') as f:\n",
    "        # Write header comment\n",
    "        f.write(\"# string_id dom_id type_id\\n\")\n",
    "        f.write(\"# Generated automatically - preserves upgrade types, sets others to type 1\\n\")\n",
    "        \n",
    "        for string_id, dom_id in sorted(all_doms):\n",
    "            if (string_id, dom_id) in existing_types:\n",
    "                # Use existing type (3 or 4 for upgrade DOMs)\n",
    "                dom_type = existing_types[(string_id, dom_id)]\n",
    "            else:\n",
    "                # Set to type 1 (standard IceCube DOM)\n",
    "                dom_type = 1\n",
    "            \n",
    "            f.write(f\"{string_id} {dom_id} {dom_type}\\n\")\n",
    "    \n",
    "    print(f\"Complete om.map written to: {output_file}\")\n",
    "    \n",
    "    # Show summary\n",
    "    type_counts = {}\n",
    "    with open(output_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if not line.startswith('#') and line.strip():\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 3:\n",
    "                    dom_type = int(parts[2])\n",
    "                    type_counts[dom_type] = type_counts.get(dom_type, 0) + 1\n",
    "    \n",
    "    print(\"\\nSummary of DOM types:\")\n",
    "    for dom_type, count in sorted(type_counts.items()):\n",
    "        type_name = {\n",
    "            1: \"Standard IceCube DOM\",\n",
    "            3: \"mDOM (upgrade)\",  \n",
    "            4: \"DEgg (upgrade)\"\n",
    "        }.get(dom_type, f\"Type {dom_type}\")\n",
    "        print(f\"  Type {dom_type} ({type_name}): {count} DOMs\")\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Generating complete om.map file...\")\n",
    "    output_file = generate_complete_om_map(geo_file, existing_om_map, output_om_map)\n",
    "    \n",
    "    print(f\"\\nTo use the new om.map file:\")\n",
    "    print(f\"mv {output_file} {existing_om_map}\")\n",
    "    print(\"\\nThen run your simulation again with NEXTGENDIR set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating complete om.map file...\n",
      "Reading geometry file...\n",
      "Found 5783 DOMs in geometry file\n",
      "Reading existing om.map...\n",
      "Found 623 DOMs with existing types\n",
      "Created backup: /groups/icecube/jackp/prometheus_genie_cleaned/harvard-prometheus/resources/PPC_tables/upgrade_tables/om.map.backup\n",
      "Generating complete om.map...\n",
      "Complete om.map written to: /groups/icecube/jackp/prometheus_genie_cleaned/harvard-prometheus/resources/PPC_tables/upgrade_tables/om.map.new\n",
      "\n",
      "Summary of DOM types:\n",
      "  Type 1 (Standard IceCube DOM): 5160 DOMs\n",
      "  Type 3 (mDOM (upgrade)): 357 DOMs\n",
      "  Type 4 (DEgg (upgrade)): 266 DOMs\n",
      "\n",
      "To use the new om.map file:\n",
      "mv /groups/icecube/jackp/prometheus_genie_cleaned/harvard-prometheus/resources/PPC_tables/upgrade_tables/om.map.new /groups/icecube/jackp/prometheus_genie_cleaned/harvard-prometheus/resources/PPC_tables/upgrade_tables/om.map\n",
      "\n",
      "Then run your simulation again with NEXTGENDIR set.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Generating complete om.map file...\")\n",
    "output_file = generate_complete_om_map(geo_file, existing_om_map, output_om_map)\n",
    "\n",
    "print(f\"\\nTo use the new om.map file:\")\n",
    "print(f\"mv {output_file} {existing_om_map}\")\n",
    "print(\"\\nThen run your simulation again with NEXTGENDIR set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing DOM mismatch between geometry and om.map...\n",
      "Reading geometry file...\n",
      "Found 5783 DOMs in geometry file\n",
      "Reading om.map...\n",
      "Found 5783 entries in om.map\n",
      "\n",
      "Geometry file has 5783 unique (string, dom) pairs\n",
      "om.map has 5783 unique (string, dom) pairs\n",
      "\n",
      "DOMs in om.map but NOT in geometry: 0\n",
      "\n",
      "DOMs in geometry but NOT in om.map: 0\n",
      "\n",
      "Checking specific problem DOM (84, 430):\n",
      "  In geometry file: False\n",
      "  In om.map: False\n",
      "\n",
      "Analyzing string 84 in detail:\n",
      "  String 84 DOMs in geometry: 60\n",
      "    DOM IDs: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]...\n",
      "    Range: 1 to 60\n",
      "  String 84 DOMs in om.map: 60\n",
      "    DOM IDs: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]...\n",
      "    Range: 1 to 60\n",
      "\n",
      "Checking for duplicates in om.map:\n",
      "  Found 0 duplicate entries in om.map\n",
      "\n",
      "============================================================\n",
      "SUMMARY:\n",
      "The issue is likely that om.map contains DOMs that don't exist in the geometry file.\n",
      "Your simulation is generating hits for these 'phantom' DOMs.\n",
      "\n",
      "To fix: Remove entries from om.map that aren't in the geometry file,\n",
      "or check if you're using the wrong geometry file.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Debug script to find the mismatch between geometry file and om.map\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# File paths - update these to your actual paths\n",
    "geo_file = \"/groups/icecube/jackp/prometheus_genie_cleaned/harvard-prometheus/resources/geofiles/icecube_upgrade_new.geo\"\n",
    "om_map_file = \"/groups/icecube/jackp/prometheus_genie_cleaned/harvard-prometheus/resources/PPC_tables/upgrade_tables/om.map\"\n",
    "\n",
    "def read_geometry_file(geo_file):\n",
    "    \"\"\"Read geometry file and extract all DOM info\"\"\"\n",
    "    doms = []\n",
    "    with open(geo_file, 'r') as f:\n",
    "        for line_num, line in enumerate(f, 1):\n",
    "            line = line.strip()\n",
    "            if line.startswith('#') or not line:\n",
    "                continue\n",
    "            \n",
    "            parts = line.split()\n",
    "            if len(parts) >= 5:\n",
    "                try:\n",
    "                    x, y, z = float(parts[0]), float(parts[1]), float(parts[2])\n",
    "                    string_id = int(parts[3])\n",
    "                    dom_id = int(parts[4])\n",
    "                    doms.append({\n",
    "                        'line_num': line_num,\n",
    "                        'x': x, 'y': y, 'z': z,\n",
    "                        'string_id': string_id, \n",
    "                        'dom_id': dom_id,\n",
    "                        'key': (string_id, dom_id)\n",
    "                    })\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error parsing line {line_num}: {line}\")\n",
    "                    print(f\"Error: {e}\")\n",
    "    \n",
    "    return doms\n",
    "\n",
    "def read_om_map(om_map_file):\n",
    "    \"\"\"Read om.map and extract all entries\"\"\"\n",
    "    om_entries = []\n",
    "    with open(om_map_file, 'r') as f:\n",
    "        for line_num, line in enumerate(f, 1):\n",
    "            line = line.strip()\n",
    "            if line.startswith('#') or not line:\n",
    "                continue\n",
    "                \n",
    "            parts = line.split()\n",
    "            if len(parts) >= 3:\n",
    "                try:\n",
    "                    string_id = int(parts[0])\n",
    "                    dom_id = int(parts[1])\n",
    "                    dom_type = int(parts[2])\n",
    "                    om_entries.append({\n",
    "                        'line_num': line_num,\n",
    "                        'string_id': string_id,\n",
    "                        'dom_id': dom_id,\n",
    "                        'type': dom_type,\n",
    "                        'key': (string_id, dom_id)\n",
    "                    })\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error parsing om.map line {line_num}: {line}\")\n",
    "                    print(f\"Error: {e}\")\n",
    "    \n",
    "    return om_entries\n",
    "\n",
    "def analyze_mismatch(geo_file, om_map_file):\n",
    "    \"\"\"Analyze mismatches between geometry and om.map\"\"\"\n",
    "    \n",
    "    print(\"Reading geometry file...\")\n",
    "    geo_doms = read_geometry_file(geo_file)\n",
    "    print(f\"Found {len(geo_doms)} DOMs in geometry file\")\n",
    "    \n",
    "    print(\"Reading om.map...\")\n",
    "    om_entries = read_om_map(om_map_file)\n",
    "    print(f\"Found {len(om_entries)} entries in om.map\")\n",
    "    \n",
    "    # Convert to sets for comparison\n",
    "    geo_keys = set(dom['key'] for dom in geo_doms)\n",
    "    om_keys = set(entry['key'] for entry in om_entries)\n",
    "    \n",
    "    print(f\"\\nGeometry file has {len(geo_keys)} unique (string, dom) pairs\")\n",
    "    print(f\"om.map has {len(om_keys)} unique (string, dom) pairs\")\n",
    "    \n",
    "    # Find mismatches\n",
    "    in_om_not_geo = om_keys - geo_keys\n",
    "    in_geo_not_om = geo_keys - om_keys\n",
    "    \n",
    "    print(f\"\\nDOMs in om.map but NOT in geometry: {len(in_om_not_geo)}\")\n",
    "    if in_om_not_geo:\n",
    "        print(\"First 10 examples:\")\n",
    "        for i, key in enumerate(sorted(in_om_not_geo)[:10]):\n",
    "            print(f\"  {key}\")\n",
    "        if len(in_om_not_geo) > 10:\n",
    "            print(f\"  ... and {len(in_om_not_geo) - 10} more\")\n",
    "    \n",
    "    print(f\"\\nDOMs in geometry but NOT in om.map: {len(in_geo_not_om)}\")\n",
    "    if in_geo_not_om:\n",
    "        print(\"First 10 examples:\")\n",
    "        for i, key in enumerate(sorted(in_geo_not_om)[:10]):\n",
    "            print(f\"  {key}\")\n",
    "        if len(in_geo_not_om) > 10:\n",
    "            print(f\"  ... and {len(in_geo_not_om) - 10} more\")\n",
    "    \n",
    "    # Check specific problematic DOM\n",
    "    problem_dom = (84, 430)\n",
    "    print(f\"\\nChecking specific problem DOM {problem_dom}:\")\n",
    "    print(f\"  In geometry file: {problem_dom in geo_keys}\")\n",
    "    print(f\"  In om.map: {problem_dom in om_keys}\")\n",
    "    \n",
    "    # Check string 84 in detail\n",
    "    print(f\"\\nAnalyzing string 84 in detail:\")\n",
    "    string_84_geo = [dom for dom in geo_doms if dom['string_id'] == 84]\n",
    "    string_84_om = [entry for entry in om_entries if entry['string_id'] == 84]\n",
    "    \n",
    "    print(f\"  String 84 DOMs in geometry: {len(string_84_geo)}\")\n",
    "    if string_84_geo:\n",
    "        dom_ids_geo = sorted([dom['dom_id'] for dom in string_84_geo])\n",
    "        print(f\"    DOM IDs: {dom_ids_geo[:10]}{'...' if len(dom_ids_geo) > 10 else ''}\")\n",
    "        print(f\"    Range: {min(dom_ids_geo)} to {max(dom_ids_geo)}\")\n",
    "    \n",
    "    print(f\"  String 84 DOMs in om.map: {len(string_84_om)}\")\n",
    "    if string_84_om:\n",
    "        dom_ids_om = sorted([entry['dom_id'] for entry in string_84_om])\n",
    "        print(f\"    DOM IDs: {dom_ids_om[:10]}{'...' if len(dom_ids_om) > 10 else ''}\")\n",
    "        print(f\"    Range: {min(dom_ids_om)} to {max(dom_ids_om)}\")\n",
    "    \n",
    "    # Check for duplicate entries\n",
    "    print(f\"\\nChecking for duplicates in om.map:\")\n",
    "    om_key_counts = {}\n",
    "    for entry in om_entries:\n",
    "        key = entry['key']\n",
    "        if key in om_key_counts:\n",
    "            om_key_counts[key] += 1\n",
    "        else:\n",
    "            om_key_counts[key] = 1\n",
    "    \n",
    "    duplicates = {k: v for k, v in om_key_counts.items() if v > 1}\n",
    "    print(f\"  Found {len(duplicates)} duplicate entries in om.map\")\n",
    "    if duplicates:\n",
    "        for key, count in list(duplicates.items())[:5]:\n",
    "            print(f\"    {key}: appears {count} times\")\n",
    "    \n",
    "    return {\n",
    "        'geo_doms': geo_doms,\n",
    "        'om_entries': om_entries,\n",
    "        'in_om_not_geo': in_om_not_geo,\n",
    "        'in_geo_not_om': in_geo_not_om,\n",
    "        'duplicates': duplicates\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Analyzing DOM mismatch between geometry and om.map...\")\n",
    "    results = analyze_mismatch(geo_file, om_map_file)\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"SUMMARY:\")\n",
    "    print(f\"The issue is likely that om.map contains DOMs that don't exist in the geometry file.\")\n",
    "    print(f\"Your simulation is generating hits for these 'phantom' DOMs.\")\n",
    "    print(f\"\\nTo fix: Remove entries from om.map that aren't in the geometry file,\")\n",
    "    print(f\"or check if you're using the wrong geometry file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv with Intel)",
   "language": "python",
   "name": "myenv_with_intel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
